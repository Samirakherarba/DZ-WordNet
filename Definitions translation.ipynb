{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " T5 google model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Faycal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "tokenizer = T5Tokenizer.from_pretrained('google/mt5-large')\n",
    "model = T5ForConditionalGeneration.from_pretrained('google/mt5-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('csv', data_files={'translation': './dataset_for_training.csv'}, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mot en fr': 'saisir', 'Daridja arabe': 'حكم'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['translation'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    source_tokens = tokenizer.encode_plus(\n",
    "        example[\"Mot en fr\"],  \n",
    "        max_length=20,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    target_tokens = tokenizer.encode_plus(\n",
    "        example[\"Daridja arabe\"], \n",
    "        max_length=20,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": source_tokens[\"input_ids\"].flatten(),\n",
    "        \"attention_mask\": source_tokens[\"attention_mask\"].flatten(),\n",
    "        \"labels\": target_tokens[\"input_ids\"].flatten()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([  327, 45144,     1,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([  259, 18197,     1,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])}\n"
     ]
    }
   ],
   "source": [
    "example = dataset[\"translation\"][0]  \n",
    "tokenized_example = tokenize_function(example)\n",
    "print(tokenized_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset[\"translation\"].filter(lambda x: x[\"Mot en fr\"] is not None and x[\"Daridja arabe\"] is not None)\n",
    "tokenized_dataset = tokenized_dataset.map(tokenize_function, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Mot en fr', 'Daridja arabe', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14954\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Mot en fr', 'Daridja arabe', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3739\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    bleu_score = corpus_bleu([[ref] for ref in labels_str], pred_str)\n",
    "\n",
    "    return {\"bleu_score\": bleu_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_checkpoint_dir = \"./Modal1\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./Modal1\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_steps=500,  \n",
    "    overwrite_output_dir=False,  \n",
    "    resume_from_checkpoint=resume_checkpoint_dir  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab14518f593e4e56879e8f9453eba93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.6189, 'grad_norm': 2.1504368782043457, 'learning_rate': 4.8663101604278076e-05, 'epoch': 0.27}\n",
      "{'loss': 0.7574, 'grad_norm': 0.910918653011322, 'learning_rate': 4.732620320855615e-05, 'epoch': 0.53}\n",
      "{'loss': 0.681, 'grad_norm': 0.7778192162513733, 'learning_rate': 4.598930481283423e-05, 'epoch': 0.8}\n",
      "{'loss': 0.6446, 'grad_norm': 0.9133714437484741, 'learning_rate': 4.4652406417112304e-05, 'epoch': 1.07}\n",
      "{'loss': 0.5912, 'grad_norm': 1.6034926176071167, 'learning_rate': 4.331550802139038e-05, 'epoch': 1.34}\n",
      "{'loss': 0.5784, 'grad_norm': 0.7972973585128784, 'learning_rate': 4.197860962566845e-05, 'epoch': 1.6}\n",
      "{'loss': 0.5728, 'grad_norm': 1.0540673732757568, 'learning_rate': 4.0641711229946525e-05, 'epoch': 1.87}\n",
      "{'loss': 0.5353, 'grad_norm': 1.4703896045684814, 'learning_rate': 3.93048128342246e-05, 'epoch': 2.14}\n",
      "{'loss': 0.5068, 'grad_norm': 1.052030086517334, 'learning_rate': 3.796791443850268e-05, 'epoch': 2.41}\n",
      "{'loss': 0.5069, 'grad_norm': 1.119246006011963, 'learning_rate': 3.6631016042780753e-05, 'epoch': 2.67}\n",
      "{'loss': 0.5034, 'grad_norm': 0.73586505651474, 'learning_rate': 3.529411764705883e-05, 'epoch': 2.94}\n",
      "{'loss': 0.4687, 'grad_norm': 0.8226745128631592, 'learning_rate': 3.39572192513369e-05, 'epoch': 3.21}\n",
      "{'loss': 0.4591, 'grad_norm': 0.8904627561569214, 'learning_rate': 3.2620320855614975e-05, 'epoch': 3.48}\n",
      "{'loss': 0.4589, 'grad_norm': 0.7578887939453125, 'learning_rate': 3.128342245989305e-05, 'epoch': 3.74}\n",
      "{'loss': 0.4498, 'grad_norm': 0.8590931296348572, 'learning_rate': 2.9946524064171122e-05, 'epoch': 4.01}\n",
      "{'loss': 0.4155, 'grad_norm': 0.8416089415550232, 'learning_rate': 2.8609625668449196e-05, 'epoch': 4.28}\n",
      "{'loss': 0.4173, 'grad_norm': 0.7122125029563904, 'learning_rate': 2.7272727272727273e-05, 'epoch': 4.55}\n",
      "{'loss': 0.4144, 'grad_norm': 0.7922715544700623, 'learning_rate': 2.5935828877005347e-05, 'epoch': 4.81}\n",
      "{'loss': 0.4128, 'grad_norm': 1.4970874786376953, 'learning_rate': 2.4598930481283424e-05, 'epoch': 5.08}\n",
      "{'loss': 0.3862, 'grad_norm': 0.9522221088409424, 'learning_rate': 2.32620320855615e-05, 'epoch': 5.35}\n",
      "{'loss': 0.3889, 'grad_norm': 0.758745551109314, 'learning_rate': 2.192513368983957e-05, 'epoch': 5.61}\n",
      "{'loss': 0.3787, 'grad_norm': 0.761408805847168, 'learning_rate': 2.058823529411765e-05, 'epoch': 5.88}\n",
      "{'loss': 0.3762, 'grad_norm': 0.9881584644317627, 'learning_rate': 1.9251336898395722e-05, 'epoch': 6.15}\n",
      "{'loss': 0.3551, 'grad_norm': 0.6850549578666687, 'learning_rate': 1.7914438502673796e-05, 'epoch': 6.42}\n",
      "{'loss': 0.3639, 'grad_norm': 1.1036587953567505, 'learning_rate': 1.6577540106951873e-05, 'epoch': 6.68}\n",
      "{'loss': 0.3615, 'grad_norm': 1.33849036693573, 'learning_rate': 1.5240641711229947e-05, 'epoch': 6.95}\n",
      "{'loss': 0.3397, 'grad_norm': 1.690130352973938, 'learning_rate': 1.3903743315508022e-05, 'epoch': 7.22}\n",
      "{'loss': 0.3454, 'grad_norm': 1.0579711198806763, 'learning_rate': 1.2566844919786098e-05, 'epoch': 7.49}\n",
      "{'loss': 0.341, 'grad_norm': 1.0972784757614136, 'learning_rate': 1.1229946524064172e-05, 'epoch': 7.75}\n",
      "{'loss': 0.3458, 'grad_norm': 0.9292057752609253, 'learning_rate': 9.893048128342247e-06, 'epoch': 8.02}\n",
      "{'loss': 0.3244, 'grad_norm': 0.9827554821968079, 'learning_rate': 8.556149732620321e-06, 'epoch': 8.29}\n",
      "{'loss': 0.3274, 'grad_norm': 1.4099150896072388, 'learning_rate': 7.2192513368983955e-06, 'epoch': 8.56}\n",
      "{'loss': 0.3267, 'grad_norm': 1.0601311922073364, 'learning_rate': 5.882352941176471e-06, 'epoch': 8.82}\n",
      "{'loss': 0.325, 'grad_norm': 0.8129891157150269, 'learning_rate': 4.5454545454545455e-06, 'epoch': 9.09}\n",
      "{'loss': 0.3234, 'grad_norm': 0.862271249294281, 'learning_rate': 3.208556149732621e-06, 'epoch': 9.36}\n",
      "{'loss': 0.3126, 'grad_norm': 0.8069100379943848, 'learning_rate': 1.8716577540106951e-06, 'epoch': 9.63}\n",
      "{'loss': 0.318, 'grad_norm': 0.9965262413024902, 'learning_rate': 5.347593582887701e-07, 'epoch': 9.89}\n",
      "{'train_runtime': 133181.6806, 'train_samples_per_second': 1.123, 'train_steps_per_second': 0.14, 'train_loss': 0.6244368425665054, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18700, training_loss=0.6244368425665054, metrics={'train_runtime': 133181.6806, 'train_samples_per_second': 1.123, 'train_steps_per_second': 0.14, 'total_flos': 1.746864549888e+16, 'train_loss': 0.6244368425665054, 'epoch': 10.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
